{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Framework - Exercise: Convolution and Pooling Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Introduction](#Introduction) \n",
    "* [Requirements](#Requirements) \n",
    "  * [Knowledge](#Knowledge)\n",
    "  * [Modules](#Python-Modules) \n",
    "  * [Data](#Data)\n",
    "* [Utility functions](#Utility-classes-and-functions)  \n",
    "  * [im2col/col2im](#im2col/col2im)\n",
    "  * [Initializer](#Initializer)\n",
    "* [Convolutional Layer](#Convolutional-Layer)\n",
    "  * [Exercise: Vectorized Implementation](#Vectorized-Implementation-Convolutional-Layer)\n",
    "  * [Testing your Implementation](#Test-Your-Conv-Implementation)\n",
    "* [Pooling Layer](#Pooling-Layer)\n",
    "  * [Exercise: Vectorized MaxPooling](#Vectorized-Implementation-MaxPooling-Layer)\n",
    "  * [Testing your Implementation](#Test-Your-Pooling-Implementation)\n",
    "* [Outlook](#Outlook)\n",
    "* [Licenses](#Licenses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this exercise, you will continue to implement the neural network framework that you started in exercise e06_nn_framework. At the end of this exercise, the framework should be extended by a convolutional layer and a pooling layer so that you can create simple ConvNets. You want your operations, especially the convolution, to be efficient, so it will not slow down the training process to an unacceptable rate. Therefore your goal is to implement vectorized versions of the layers in the exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    "## Knowledge\n",
    "\n",
    "At this point, you should have a good understanding of how a convolutional layer works. At least, you should have solved the exercises **exercise-nn-framework** and **exercise-conv-net-pen-and-paper** before doing this exercise. Exercise **exercise-nn-framework** provided you with the necessary information about the framework architecture that you need. Exercise **exercise-conv-net-pen-and-paper** gave you the theoretical background about the vectorization of the convolutional layer.\n",
    "\n",
    "You can find both of these exercises in the [Convolutional Neural Networks](#https://dev.deep-teaching.org/courses/cnns) course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python-Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "while your implementation is intended to work with any given image data $X$, you will also use some tweaked values, e.g. the toy example $I_{toy}$ and the kernel $K_{toy}$ during this exercise so you are able to verify your results. As $I_{toy}$ and $K_{toy}$ you will use the data from exercise-conv-net-pen-and-paper, so you know already the results of the covolutional operation and the backward pass (if $dout$ is a all-ones matrix) for the hyperparameter setting stride $s = 2$ and padding $p = 0$. \n",
    "\n",
    "$$\n",
    "I_{toy} = \\left[ \\begin{array} { c c c c c } { 1 } & { 1 } & { - 2 } & { 0 } & { 1 } \\\\ { 1 } & { 0 } & { 0 } & { 2 } & { 1 } \\\\ { 0 } & { 1 } & { 0 } & { 5 } & { - 1 } \\\\ { - 2 } & { 1 } & { 0 } & { - 1 } & { 1 } \\\\ { 0 } & { 1 } & { 0 } & { 5 } & { - 1 } \\end{array} \\right] , K_{toy} = \\left[ \\begin{array} { c c c } { 0 } & { 1 } & { 1 } \\\\ { 1 } & { 0 } & { 0 } \\\\ { 0 } & { 1 } & { 0 } \\end{array} \\right] ,  dout_{toy} = \\left[ \\begin{array} { c c c } { 1 } & { 1 } \\\\ { 1 } & { 1 } \\end{array} \\right]\n",
    "$$\n",
    "\n",
    "$K_{toy}$ will be defined later on in the section [Initializer](#Initializer).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images \n",
    "X = np.random.randn(600, 1, 28, 28)\n",
    "I_toy = np.array([[[[1,1,-2,0,1],[1,0,0,2,1],[0,1,0,5,-1],[-2,1,0,-1,1],[0,1,0,5,-1]]]])\n",
    "\n",
    "# Upflowing toy gradients \n",
    "dout_toy = np.array([[[[1.,1.],[1.,1.]]]])\n",
    "\n",
    "#print('X shape:', X.shape)\n",
    "#print('X:', X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility classes and functions\n",
    "\n",
    "The following classes and functions are utilities to vectorize the convolutional operation and to initialize learnable parameters with different methods. You can put these into the `utils.py` file of your framework after the exercise. Be sure to read them carefully and figure out how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## im2col/col2im Functions\n",
    "\n",
    "The following methods are taken from [cs231 Convolutional Neural Network assignment 2](http://cs231n.github.io/assignments2018/assignment2/) and have been modified for square images. They represent a compact implementation of the [im2col approach](https://hal.inria.fr/inria-00112631/document) to vectorize the convolutional operation. You should be familiar with the theory behind that approach. Now let us have a closer look at the implementation, which splits into three methods `get_indices`, `im2col` and `col2im`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_indices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to transform an image $I$ to the im2col vector $\\vec{i}$. For image dimensions (5x5), kernel dimension $(3,3)$ and hyperparameters stride $S = 2$, padding $P = 0$ following applies:\n",
    "\n",
    "$$\n",
    "I_{5x5} = \\left[\n",
    "\\begin{matrix}\n",
    "i_{1,1} & i_{1,2} & i_{1,3} & i_{1,4} & i_{1,5} \\\\\n",
    "i_{2,1} & i_{2,2} & i_{2,3} & i_{2,4} & i_{2,5}\\\\\n",
    "i_{3,1} & i_{3,2} & i_{3,3} & i_{3,4} & i_{3,5}\\\\\n",
    "i_{4,1} & i_{4,2} & i_{4,3} & i_{4,4} & i_{4,5}\\\\\n",
    "i_{5,1} & i_{5,2} & i_{5,3} & i_{5,4} & i_{5,5}\\\\\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "The corresponding im2col matrix should look like:\n",
    "\n",
    "$$\n",
    "\\vec{i} = \\left[ \n",
    "\\begin{matrix}\n",
    "i_{1,1} & i_{1,3} & i_{3,1} & i_{3,3} \\\\\n",
    "i_{1,2} & i_{1,4} & i_{3,2} & i_{3,4} \\\\\n",
    "i_{1,3} & i_{1,5} & i_{3,3} & i_{3,5} \\\\\n",
    "i_{2,1} & i_{2,3} & i_{4,1} & i_{4,3} \\\\\n",
    "i_{2,2} & i_{2,4} & i_{4,2} & i_{4,4} \\\\\n",
    "i_{2,3} & i_{2,5} & i_{4,3} & i_{4,5} \\\\\n",
    "i_{3,1} & i_{3,3} & i_{5,1} & i_{5,3} \\\\\n",
    "i_{3,2} & i_{3,4} & i_{5,2} & i_{5,4} \\\\\n",
    "i_{3,3} & i_{3,5} & i_{5,3} & i_{5,5} \\\\\n",
    "\\end{matrix}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we look at the $i$-th and $j$-th index individually, we can store each index in its own matrix. That is what the `get_indices()` does for you.  The corresponding matrix for the $i$-th index would be\n",
    "\n",
    "$$\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "1 & 1 & 3 & 3 \\\\\n",
    "1 & 1 & 3 & 3 \\\\\n",
    "1 & 1 & 3 & 3 \\\\\n",
    "2 & 2 & 4 & 4 \\\\\n",
    "2 & 2 & 4 & 4 \\\\\n",
    "2 & 2 & 4 & 4 \\\\\n",
    "3 & 3 & 5 & 5 \\\\\n",
    "3 & 3 & 5 & 5 \\\\\n",
    "3 & 3 & 5 & 5 \\\\\n",
    "\\end{matrix}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and for the $j$-th index:\n",
    "\n",
    "$$\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "1 & 3 & 1 & 3 \\\\\n",
    "2 & 4 & 2 & 4 \\\\\n",
    "3 & 5 & 3 & 5 \\\\\n",
    "1 & 3 & 1 & 3 \\\\\n",
    "2 & 4 & 2 & 4 \\\\\n",
    "3 & 5 & 3 & 5 \\\\\n",
    "1 & 3 & 1 & 3 \\\\\n",
    "2 & 4 & 2 & 4 \\\\\n",
    "3 & 5 & 3 & 5 \\\\\n",
    "\\end{matrix}\\right]\n",
    "$$\n",
    "\n",
    "These two matrices are the variables `i` and `j` are given by the method `get_indices` as the 2nd and 3rd element of the returned tuple. For simplification, we have a trivial depth dimension $c$ in the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(x_shape, filter_dim=(3, 3), padding=0, stride=1):\n",
    "    '''Gets the incides in which the elements of your matrix has to be inserted \n",
    "       in order to transform then into a im2col matrix.\n",
    "\n",
    "    Args:\n",
    "        x_shape: Shape of the input data\n",
    "        filter_dim: i-th and j-th filter dimensions, e.g., (3,3) \n",
    "        padding: Layer padding size \n",
    "        stride: Layer stride size \n",
    "   \n",
    "    Returns:\n",
    "        im2col indices as 3-tuple (c,i, j) - (channel indices, col indices, \n",
    "                                              row indices)\n",
    "    '''\n",
    "    # get shape of the input data and calculate output dimensions\n",
    "    # beause we deal with squared images we don't have to calculate it twice\n",
    "    N, C, H, W = x_shape\n",
    "    out_size = (H + 2 * padding - filter_dim[0]) // stride + 1  # // to get an int() instead of float()\n",
    "    #out_size = int(out_size)\n",
    "\n",
    "    # calculate the indices of the channel dimension\n",
    "    c = np.repeat(np.arange(C), filter_dim[0] * filter_dim[1]).reshape(-1, 1)\n",
    "\n",
    "    # calculating the indices of the width & height dimension\n",
    "    # repeat() and tile() are used to multiply the wanted sequences\n",
    "    i0 = np.repeat(np.arange(filter_dim[0]), filter_dim[1])\n",
    "    i0 = np.tile(i0, C)\n",
    "    i1 = stride * np.repeat(np.arange(out_size), out_size)\n",
    "    j0 = np.tile(np.arange(filter_dim[0]), filter_dim[1] * C)\n",
    "    j1 = stride * np.tile(np.arange(out_size), out_size)\n",
    "    \n",
    "    i = i0.reshape(-1, 1) + i1.reshape(1, -1)\n",
    "    j = j0.reshape(-1, 1) + j1.reshape(1, -1)\n",
    "    return (c, i, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### im2col()\n",
    "\n",
    "The function `im2col()` transforms an image $I$ into the desired representation using the indices from `get_indices()`. For the toy example $I_{toy}$, a $(5x5)$-matrix with concrete values, we expect the following:\n",
    "\n",
    "$$\n",
    "I_{toy} = \\left[ \\begin{array} { c c c c c } { 1 } & { 1 } & { - 2 } & { 0 } & { 1 } \\\\ { 1 } & { 0 } & { 0 } & { 2 } & { 1 } \\\\ { 0 } & { 1 } & { 0 } & { 5 } & { - 1 } \\\\ { - 2 } & { 1 } & { 0 } & { - 1 } & { 1 } \\\\ { 0 } & { 1 } & { 0 } & { 5 } & { - 1 } \\end{array} \\right]\n",
    "$$\n",
    "\n",
    "\n",
    "You know from the exercise exercise-conv-net-pen-and-paper that the im2col matrix of $I_{toy}$ should look like: \n",
    "\n",
    "$$\n",
    "\\vec{i} = \n",
    "\\left[\n",
    "\\begin{matrix}\n",
    " 1 & -2 &  0 &  0 \\\\\n",
    " 1 &  0 &  1 &  5 \\\\\n",
    "-2 &  1 &  0 & -1 \\\\\n",
    " 1 &  0 & -2 &  0 \\\\\n",
    " 0 &  2 &  1 & -1 \\\\\n",
    " 0 &  1 &  0 &  1 \\\\\n",
    " 0 &  0 &  0 &  0 \\\\\n",
    " 1 &  5 &  1 &  5 \\\\\n",
    " 0 & -1 &  0 & -1 \n",
    "\\end{matrix}\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(x, filter_dim=(3, 3), padding=0, stride=1):\n",
    "    ''' Transforms a image matrix to im2col matrix. \n",
    "    \n",
    "    Assume you have a image of shape (600, 1, 28, 28), padding=0, \n",
    "    stride=2 and a filter with dimensions (3,3). You already know \n",
    "    that the output dimension of a convolution operator has to be \n",
    "    (13,13) with (28-3)/2 + 1 = 13.\n",
    "    im2col creates then a new matrix with the shape of (9 * 1, 600 * 13 * 13)\n",
    "    which you then can matrix multiply with your flattend kernel of shape \n",
    "    (n,9 * 1). The multiplication will result into a new matrix of shape \n",
    "    (n,600*13*13) which you can then reshape into your convolution \n",
    "    output (600, n, 13, 13) which is the wanted result. Note that n is\n",
    "    the numbers of filters inside your convolution layer.\n",
    "    \n",
    "    Args:\n",
    "        x: Input data\n",
    "        filter_dim: i-th and j-th filter dimensions, e.g., (3,3)\n",
    "        padding: Layer padding size\n",
    "        stride: Layer stride size\n",
    "        \n",
    "    Returns:\n",
    "        im2col matrix e.g. in our example with shape (9 * 1, 600 * 13 * 13)\n",
    "    '''\n",
    "    # Zero-pad the input\n",
    "    p = padding\n",
    "    x_padded = np.pad(x, ((0, 0), (0, 0), (p, p), (p, p)), mode='constant')\n",
    "    \n",
    "    # get the indices of the column matrix\n",
    "    c, i, j = get_indices(x.shape, filter_dim, padding, stride)\n",
    "    \n",
    "    # create the col matrix by using the indices from above\n",
    "    # Hint: cols should have a shape of (9 * 1, 600 * 13 * 13) in the example given by the documentation.\n",
    "    # cols = TODO\n",
    "    cols = x_padded[:, c, i, j]\n",
    "    cols = cols.transpose(1, 2, 0)\n",
    "\n",
    "    # transforming the matrix to the desired shape, e.g., (9 * 1, 600 * 13 * 13)\n",
    "    cols = cols.reshape(filter_dim[0] * filter_dim[1] * x.shape[1], -1)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example and reproduction of the result from e08\n",
    "print('I_toy transformed with im2col:')\n",
    "print(im2col(I_toy, stride=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### col2im()\n",
    "\n",
    "The function `col2im()` is the inverse function to `im2col()`. In general, you use the `col2im`-function to convert the gradient $ \\frac{\\partial L}{\\partial I}$ from its `im2col`-matrix representation back into the initial shape of the input. This assumes that you use the same hyperparameter settings as in the `im2col` transformation.\n",
    "\n",
    "The `im2col`-matrix that we get as a result of the backward path in the convolutional layer for the toy example is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial I_{toy\\_col}} = \n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "1 & 1 & 1 & 1 \\\\\n",
    "1 & 1 & 1 & 1 \\\\\n",
    "1 & 1 & 1 & 1 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "1 & 1 & 1 & 1 \\\\\n",
    "0 & 0 & 0 & 0 \n",
    "\\end{matrix}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "From the optional exercise in e08 you should know that the correct gradient $\\frac{\\partial L}{\\partial I_{toy}}$ is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial I_{toy}} =  \\left[\n",
    "\\begin{matrix}\n",
    "0 & 1 & 1 & 1 & 1 \\\\\n",
    "1 & 0 & 1 & 0 & 0 \\\\\n",
    "0 & 2 & 1 & 2 & 1 \\\\\n",
    "1 & 0 & 1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 1 & 0\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "Exactly these values you get if you use `col2im()` with the $\\frac{\\partial L}{\\partial I_{toy\\_col}}$ matrix and a hyperparamter setting of stride $S = 2$ and padding $P = 0$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im(cols, x_shape, filter_dim=(3, 3), padding=0, stride=1):\n",
    "    ''' Transforms a im2col matrix to its initial shape.\n",
    "    \n",
    "    You can think of this method as the reverse function of im2col. It is\n",
    "    adding up the corresponing indices and transforms the given matrix\n",
    "    back into the initial shape.\n",
    "\n",
    "    Assuming you have a im2col transformed matrix with shape (9,600*13*13). \n",
    "    The original image had a shape of (600,1,28,28) with padding P = 0 \n",
    "    and stride S = 2. col2im creates out of the im2col matrix and the same\n",
    "    hyperparameter a new matrix with a shape of (600, 1, 28, 28).\n",
    "    \n",
    "    Args:\n",
    "        cols: im2col matrix\n",
    "        x_shape: Shape of the data before applying im2col transformation \n",
    "        filter_dim: Filter dimensions\n",
    "        padding: Layer padding size\n",
    "        stride: Layer stride size\n",
    "    \n",
    "    Returns:\n",
    "        Matrix with inital shape \n",
    "    '''\n",
    "    # Get shapes and padding\n",
    "    N, C, H, W = x_shape\n",
    "    padded_shape = H + 2 * padding\n",
    "\n",
    "    # Create a placeholder with initial input shape and padding used during conv \n",
    "    x_padded = np.zeros((N, C, padded_shape, padded_shape), dtype=cols.dtype)\n",
    "\n",
    "    # transform and reorder matrix to restore a im2col matrix for each sample\n",
    "    cols_reshaped = cols.reshape(C * filter_dim[0] * filter_dim[1], -1, N)\n",
    "    cols_reshaped = cols_reshaped.transpose(2, 0, 1)    \n",
    "\n",
    "    # Get same indices used in a corresponging im2col transformation. \n",
    "    # With the indices and fancy indexing add all matching indices\n",
    "    # and store them in a matrix with initial shape.\n",
    "    c, i, j = get_indices(x_shape, filter_dim, padding, stride)\n",
    "    np.add.at(x_padded, (slice(None), c, i, j), cols_reshaped)\n",
    "    \n",
    "    # if necessary remove conv padding\n",
    "    if padding == 0:\n",
    "        return x_padded\n",
    "    return x_padded[:, :, padding:-padding, padding:-padding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example and reproduction of the result from e08\n",
    "dI_toy_col =np.array([[[[0.,0.,0.,0.],\n",
    "                      [1.,1.,1.,1.],\n",
    "                      [1.,1.,1.,1.],\n",
    "                      [1.,1.,1.,1.],\n",
    "                      [0.,0.,0.,0.],\n",
    "                      [0.,0.,0.,0.],\n",
    "                      [0.,0.,0.,0.],\n",
    "                      [1.,1.,1.,1.],\n",
    "                      [0.,0.,0.,0.]]]])\n",
    "dI_toy = col2im(dI_toy_col, I_toy.shape, stride=2)\n",
    "print(dI_toy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializer\n",
    "\n",
    "Class `WeightInitializer` provides some functions to initialize the weights in your convolutional layer with different methods, e.g., [Xavier Glorot initialization technic](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf?hc_location=ufi) if you use sigmoid as activation function. You should move the class into `utils.py` after solving the exercise and develop it so that you can initialize your fully connected layer with it as well. The method `toy_initialization` is for this exercise only, and you should delete it when moving the class into the script file. You can use this method with $I_{toy}$ and $K_{toy}$ to reproduce the values of exercise-conv-net-pen-and-paper. The usage is pretty simple. When initializing a convolutional layer, you set the weight initialization as a parameter:\n",
    "\n",
    "```\n",
    "conv1 = Convolution(filter_num=16,filter_dim=(1, 3, 3), initializer=WeightInitializer.he, stride=1, padding=0)\n",
    "```\n",
    "\n",
    "However, be careful to choose a method that is appropriate for your activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightInitializer(object):\n",
    "    ''' Different weight initialization methods\n",
    "    \n",
    "    '''\n",
    "    def random(filter_num, input_channels, filter_dim):\n",
    "        ''' Initialize a kernel with random values \n",
    "        \n",
    "        Returns:\n",
    "            4d tensor (filter_number, filter_depth, filter_height, filter_weight)        \n",
    "        '''\n",
    "        random_weight = np.random.randn(filter_num, input_channels, filter_dim[0], filter_dim[1]) * 0.1\n",
    "        return random_weight\n",
    "\n",
    "    def glorot(filter_num, input_channels, filter_dim):\n",
    "        ''' Xavier Glorot initialization - used for sigmoid, tanh\n",
    "        \n",
    "        Returns:\n",
    "            4d tensor (filter_number, filter_depth, filter_height, filter_weight)\n",
    "        '''\n",
    "        glorot_weights = np.random.randn(filter_num, input_channels, filter_dim[0], filter_dim[1]) * np.sqrt(1. / filter_dim[0]) \n",
    "        return glorot_weights\n",
    "    \n",
    "    def he(filter_num, input_channels, filter_dim):\n",
    "        ''' Kaiming He initialization - used for ReLU family\n",
    "        \n",
    "        Returns:\n",
    "            4d tensor (filter_number, filter_depth, filter_height, filter_weight)\n",
    "        '''\n",
    "        he_weights = np.random.randn(filter_num, input_channels, filter_dim[0], filter_dim[1]) * np.sqrt(2. / filter_dim[0]) \n",
    "        return he_weights\n",
    "    \n",
    "    def toy_initialization(filter_num, input_channels, filter_dim):\n",
    "        ''' Only for exercise e09 test case. Initialize \n",
    "            the filter used in e08: \n",
    "            [[[[ 0.,1.,1.], \n",
    "               [ 1.,0.,0.],\n",
    "               [ 0.,1.,0.]]]])\n",
    "        '''\n",
    "        return np.array([[[[ 0.,1.,1.], [ 1.,0.,0.],[ 0.,1.,0.]]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorized Implementation Convolutional Layer\n",
    "\n",
    "**Task:**\n",
    "\n",
    "Implement a vectorized convolutional layer. The class and initialization are given. You have to implement the `forward` and `backward` path. Revisit the exercise **exercise-conv-net-pen-and-paper.pdf** if necessary to recall how a vectorized convolution is done. Then add the `Convolution` class to your already existing `layer.py` in your framework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution():\n",
    "    ''' Creates a convolutional layer\n",
    "    \n",
    "    To use:\n",
    "        conv1 = Convolution(filter_num=16,filter_dim=(1, 3, 3), \n",
    "                           initializer=WeightInitializer.he, stride=1, padding=0)\n",
    "        conv.forward(X)\n",
    "    '''\n",
    "    def __init__(self, filter_num=32, filter_dim=(1, 3, 3), initializer=WeightInitializer.random, stride=1, padding=0):\n",
    "        ''' Initilize convolution layer with given parameter\n",
    "        \n",
    "        Args:\n",
    "            filter_num: number of filters used for the convolution\n",
    "            filter_dim: (filter_depth, filter_height, filter_width) \n",
    "                        filter_depth have to be equal to input_depth\n",
    "            stride: step size to move the filter\n",
    "            padding: size of zero padding\n",
    "        '''\n",
    "        self.input_channels = filter_dim[0]\n",
    "        self.filter_num = filter_num\n",
    "        self.filter_dim = (filter_dim[1], filter_dim[2])\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        # Initialize weights and bias\n",
    "        self.W = initializer(filter_num, self.input_channels, self.filter_dim)\n",
    "        self.b = np.zeros((1, filter_num)).T\n",
    "        \n",
    "        self.params = [self.W, self.b]\n",
    "        \n",
    "    def forward(self, X, verbose=False):\n",
    "        ''' Convolution over input X to create feature maps\n",
    "        \n",
    "        Actualy implements a vectorized cross-correlation over\n",
    "        input X with the filters specified in the layer creation.\n",
    "\n",
    "        Args:\n",
    "            X: 4d tensor (num_images, num_channels, height, width)\n",
    "            verbose: If set, prints information about shapes of x_col, w_col and out\n",
    "            \n",
    "        Returns:\n",
    "            out: feature maps \n",
    "        '''\n",
    "        # Get input and weight parameter\n",
    "        n_filters, d_filter, h_filter, w_filter = self.W.shape\n",
    "        n_x, d_x, h_x, w_x = X.shape\n",
    "        \n",
    "        # Calculate feature map dimensions\n",
    "        size_out = (h_x - h_filter + 2 * self.padding) // self.stride + 1\n",
    "        \n",
    "        ##############################\n",
    "        ####### BEGIN SOLUTION ####### \n",
    "        ##############################\n",
    "\n",
    "        ############################\n",
    "        ####### END SOLUTION #######\n",
    "        ############################\n",
    "        # store input and im2col-matrix for backprop\n",
    "        self.X = X\n",
    "        self.x_col = x_col \n",
    "        return out\n",
    "\n",
    "    def backward(self, dout, verbose=False):\n",
    "        ''' Calculates the gradient with respect to the image X, the filter/kernel W and bias b.\n",
    "\n",
    "        Args:\n",
    "            dout: Gradient of the output\n",
    "            verbose: If set, prints information about shapes of db, dW and dX\n",
    "\n",
    "        Returns:\n",
    "            dX : Derivation with respect to X\n",
    "            dW : Derivation with respect to W\n",
    "            db : Derivation with respect to b\n",
    "        '''\n",
    "        n_filter, d_filter, h_filter, w_filter = self.W.shape\n",
    "\n",
    "        ##############################\n",
    "        ####### BEGIN SOLUTION ####### \n",
    "        ##############################\n",
    "\n",
    "        ############################\n",
    "        ####### END SOLUTION #######\n",
    "        ############################\n",
    "\n",
    "        return dX, [dW, db]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Your Conv Implementation\n",
    "\n",
    "There are two test cases:\n",
    "- The toy example to reproduce the values from exercise-conv-net-pen-and-paper. You can verify these results by hand.\n",
    "- A more realistic X tensor, but with a simple gradient. Your resulting shapes should match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Toy example ---\n",
    "# Create a ConvLayer with parameters from e08\n",
    "conv_toy = Convolution(filter_num=1,filter_dim=(1, 3, 3), initializer=WeightInitializer.toy_initialization, stride=2, padding=0)\n",
    "\n",
    "# Forward path\n",
    "out_toy = conv_toy.forward(I_toy)\n",
    "np.testing.assert_array_equal(out_toy, np.array([[[[1., 6.], [0., 9.]]]]), verbose=True)\n",
    "\n",
    "# Backward path \n",
    "dout_toy = np.ones((1,1,2,2)) # Gradient from e08\n",
    "dI_toy, [dW_toy, db_toy] = conv_toy.backward(dout_toy)\n",
    "np.testing.assert_array_equal(dI_toy, np.array([[[[0., 1., 1., 1., 1.], \n",
    "                                                  [1., 0., 1., 0., 0.],\n",
    "                                                  [0., 2., 1., 2., 1.],\n",
    "                                                  [1., 0., 1., 0., 0.],\n",
    "                                                  [0., 1., 0., 1., 0.]]]]), verbose=True)\n",
    "np.testing.assert_array_equal(dW_toy, np.array([[[[-1., 7., -2.], \n",
    "                                                  [-1., 2., 2.],\n",
    "                                                  [0., 12., -2.]]]]), verbose=True)\n",
    "np.testing.assert_array_equal(db_toy, np.array([[4]]), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More complex test case\n",
    "# Create a ConvLayer with appropriate filter settings\n",
    "conv1 = Convolution(filter_num=16,filter_dim=(1, 3, 3), initializer=WeightInitializer.he, stride=1, padding=0)\n",
    "\n",
    "# Forward path\n",
    "out1 = conv1.forward(X, verbose=False)\n",
    "\n",
    "#Backward path\n",
    "dout1 = np.ones((600, 16, 26, 26))\n",
    "dX1, [dW1, db1] = conv1.backward(dout1, verbose=False)\n",
    "\n",
    "# Calculate some shapes individualy and validate it against the implementation\n",
    "num, channel, height, width = X.shape\n",
    "print('Is the shape of the output correct?', out1.shape == (num, conv1.filter_num, \n",
    "                                                    (height - conv1.filter_dim[0] + 2 * conv1.padding) // conv1.stride + 1, \n",
    "                                                    (width - conv1.filter_dim[0] + 2 * conv1.padding) // conv1.stride + 1), \n",
    "                                                    out1.shape)\n",
    "print('Is the shape of input_gradients correct?', dX1.shape == X.shape, dX1.shape)\n",
    "print('Is the shape of weight_gradients correct?', dW1.shape == conv1.W.shape, dW1.shape)\n",
    "print('Is the shape of bias_gradients correct?', db1.shape == conv1.b.shape, db1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorized Implementation MaxPooling Layer\n",
    "**Task:**\n",
    "\n",
    "Implement a max pooling operation as a network layer. Move the class into the `layer.py` file of the framework after you finish your implementation. If you want you can also implement a parameter for choosing a different pooling function, e.g. `mean` or `sum`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling():\n",
    "    ''' Creates a MaxPooling layer\n",
    "    '''\n",
    "\n",
    "    def __init__(self, filter_dim=(2, 2), stride=2):\n",
    "        ''' Initialize a pooling layer with `max` as pooling function\n",
    "\n",
    "        Layer is usualy initialzied with a (2,2) filter and\n",
    "        stride 2 as parameter. Your input volume, e.g. (1,1,28,28)\n",
    "        should shrink by factor 2 -> (1,1,14,14) with this setting.\n",
    "\n",
    "        Args:\n",
    "            filter_dim: pooling size\n",
    "            stride: stride size\n",
    "        '''\n",
    "        self.filter_dim = filter_dim\n",
    "        self.stride = stride\n",
    "        self.params = []\n",
    "\n",
    "    def forward(self, X, verbose=False):\n",
    "        ''' Applies the max function to each kernel postion\n",
    "        \n",
    "        Args:\n",
    "            X: input volume - 4d tensor\n",
    "            verbose: If set, prints shapes of some volumes\n",
    "            \n",
    "        Returns:\n",
    "            4d tensor with reduced dimensions according to the chosen\n",
    "            hyperparameters and max function applied to each filter\n",
    "            position\n",
    "        '''\n",
    "        # Reshapes the images so that the depth dim is 1\n",
    "        n_x, d_x, h_x, w_x = X.shape\n",
    "        x_reshaped = X.reshape(n_x * d_x, 1, h_x, w_x)\n",
    "        \n",
    "        ##############################\n",
    "        ####### BEGIN SOLUTION ####### \n",
    "        ##############################\n",
    "        # HINT: Pooling operation is just a convolution with a different filter.\n",
    "        #       Make use im2col to get a column matrix and find the max in each\n",
    "        #       column. Store max indices in the object for use in the backprop.\n",
    "        \n",
    "        ############################\n",
    "        ####### END SOLUTION #######\n",
    "        ############################\n",
    "            \n",
    "        # Save input and input col for future use\n",
    "        self.x_col = x_col\n",
    "        self.X = X\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout, verbose=False):\n",
    "        ''' Backward path of the Maxpooling-Layer\n",
    "        \n",
    "        Remember there is no gradient calculation in a\n",
    "        max pooling layer.\n",
    "        \n",
    "        Args:\n",
    "            dout: Upflowing gradient\n",
    "            verbose: If set, prints shapes of some volumes\n",
    "            \n",
    "        Returns:\n",
    "            dX with following modification:\n",
    "             - dX values sitting on indices of max values from \n",
    "               the forward path will be passed through the layer\n",
    "             - all other values are set to zero\n",
    "        '''\n",
    "        # Save the shape of the input image\n",
    "        n_x, d_x, h_x, w_x = self.X.shape\n",
    "        \n",
    "        ##############################\n",
    "        ####### BEGIN SOLUTION ####### \n",
    "        ##############################\n",
    "        # Hint: Use the indices of the forward path and\n",
    "        #       fancy indexing to chose the right indices dX\n",
    "        \n",
    "        ############################\n",
    "        ####### END SOLUTION #######\n",
    "        ############################\n",
    "        \n",
    "        # reshaping it pack to the input image shape\n",
    "        dX = dX.reshape(self.X.shape)\n",
    "        return dX, []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Your Pooling Implementation\n",
    "\n",
    "Lets create another toy example again an use it for the max pooling layer:\n",
    "\n",
    "$$\n",
    "I_{pooling} = \\left[\n",
    "\\begin{matrix}\n",
    "0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 9 & 0 & 8 & 0 & 9 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "7 & 0 & 7 & 0 & 8 & 0 \\\\\n",
    "5 & 0 & 6 & 0 & 9 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "Use the output of the forward path as input for the backward path to recreate the original input.\n",
    "The second test inserts the more complex output tensor from the convolutional operation into a pooling layer and checks its dimensions after forward and backward path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another toy example as sanity check\n",
    "I_toy_pooling = np.array([[[[0., 0., 0., 0., 0., 0.], \n",
    "                            [0., 9., 0., 8., 0., 9.],\n",
    "                            [0., 0., 0., 0., 0., 0.],\n",
    "                            [7., 0., 7., 0., 8., 0.],\n",
    "                            [5., 0., 6., 0., 9., 0.],\n",
    "                            [0., 0., 0., 0., 0., 0.]]]])\n",
    "\n",
    "pooling_toy = Pooling(filter_dim=(2, 2), stride=2)\n",
    "out_toy_pooling = pooling_toy.forward(I_toy_pooling, verbose=True)\n",
    "\n",
    "# backward path - pooling\n",
    "dout_toy_pooling = pooling_toy.backward(out_toy_pooling, verbose=True)\n",
    "dX_toy_pooling, empty = dout_toy_pooling\n",
    "\n",
    "# Tests\n",
    "np.testing.assert_array_equal(out_toy_pooling, np.array([[[[9., 8., 9.], \n",
    "                                                           [7., 7., 8.],\n",
    "                                                           [5., 6., 9.]]]]), verbose=True)\n",
    "np.testing.assert_array_equal(dX_toy_pooling, np.array([[[[0., 0., 0., 0., 0., 0.], \n",
    "                                                          [0., 9., 0., 8., 0., 9.],\n",
    "                                                          [0., 0., 0., 0., 0., 0.],\n",
    "                                                          [7., 0., 7., 0., 8., 0.],\n",
    "                                                          [5., 0., 6., 0., 9., 0.],\n",
    "                                                          [0., 0., 0., 0., 0., 0.]]]]), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A more complex example\n",
    "# forward path - pooling\n",
    "pooling2 = Pooling(filter_dim=(2, 2), stride=2)\n",
    "out2 = pooling2.forward(out1)\n",
    "\n",
    "# backward path - pooling\n",
    "gradient2 = pooling2.backward(out2)\n",
    "dX2, empty = gradient2\n",
    "\n",
    "num, channel, height, width = out1.shape\n",
    "print('------------Pooling test------------')\n",
    "print('Output correct shape?', out2.shape == (num, \n",
    "                                              channel, \n",
    "                                              (height-pooling2.filter_dim[0])//pooling2.stride + 1, \n",
    "                                              (width-pooling2.filter_dim[0])//pooling2.stride + 1), out2.shape)\n",
    "print('Gradient correct shape?', dX2.shape == out1.shape, dX2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlook\n",
    "\n",
    "After finishing the exercise, you should have a working and efficient neural network framework. Do not forget to move all classes into the corresponding script files of the framework. A good follow up is to repeat your experiments on a dataset of your interest from **exercise-nn-framework** but with a ConvNet instead of a standard neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Licenses\n",
    "\n",
    "### Notebook License (CC-BY-SA 4.0)\n",
    "\n",
    "*The following license applies to the complete notebook, including code cells. It does however not apply to any referenced external media (e.g., images).*\n",
    "\n",
    "1163150 - Neural Networks - Exercise: Convolutional and Pooling Layer <br/>\n",
    "by Steven Mi, Benjamin Voigt <br/>\n",
    "is licensed under a [Creative Commons Attribution-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-sa/4.0/).<br/>\n",
    "Based on a work at [https://gitlab.com/deep.TEACHING](https://gitlab.com/deep.TEACHING).\n",
    "\n",
    "### Code License (MIT)\n",
    "\n",
    "*The following license only applies to code cells of the notebook.*\n",
    "\n",
    "Copyright 2018 Steven Mi, Benjamin Voigt\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "deep_teaching_kernel",
   "language": "python",
   "name": "deep_teaching_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
