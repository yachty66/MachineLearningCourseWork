{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d80f56a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndemonstrating object detection in showing the detection of my face in opencv. my face + bounding box and prob of gender must appear or human.\\nhttps://cv.gluon.ai/build/examples_detection/demo_webcam.html\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "demonstrating object detection in showing the detection of my face in opencv. my face + bounding box and prob of gender must appear or human.\n",
    "https://cv.gluon.ai/build/examples_detection/demo_webcam.html\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9e2ec4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxhager/opt/anaconda3/lib/python3.9/site-packages/gluoncv/__init__.py:40: UserWarning: Both `mxnet==1.8.0` and `torch==1.9.0.post2` are installed. You might encounter increased GPU memory footprint if both framework are used at the same time.\n",
      "  warnings.warn(f'Both `mxnet=={mx.__version__}` and `torch=={torch.__version__}` are installed. '\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import gluoncv as gcv\n",
    "from gluoncv.utils import try_import_cv2\n",
    "cv2 = try_import_cv2()\n",
    "import mxnet as mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5582560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxhager/opt/anaconda3/lib/python3.9/site-packages/mxnet/gluon/block.py:1627: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:\n",
      "\tdata: None\n",
      "  input_sym_arg_type = in_param.infer_type()[0]\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "net = gcv.model_zoo.get_model('ssd_512_mobilenet1.0_voc', pretrained=True)\n",
    "# Compile the model for faster speed\n",
    "net.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "807da931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the webcam handler\n",
    "cap = cv2.VideoCapture(0)\n",
    "time.sleep(1) ### letting the camera autofocus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9df30f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = None\n",
    "NUM_FRAMES = 200 # you can change this\n",
    "for i in range(NUM_FRAMES):\n",
    "    # Load frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Image pre-processing\n",
    "    frame = mx.nd.array(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)).astype('uint8')\n",
    "    rgb_nd, frame = gcv.data.transforms.presets.ssd.transform_test(frame, short=512, max_size=700)\n",
    "\n",
    "    # Run frame through network\n",
    "    class_IDs, scores, bounding_boxes = net(rgb_nd)\n",
    "\n",
    "    # Display the result\n",
    "    img = gcv.utils.viz.cv_plot_bbox(frame, bounding_boxes[0], scores[0], class_IDs[0], class_names=net.classes)\n",
    "    gcv.utils.viz.cv_plot_image(img)\n",
    "    cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900d3043",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "087ed4b5ae5ab8a802fc70b7204961b469aa2ba57c16f25f9d870b586c21be65"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
